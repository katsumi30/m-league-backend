from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import sqlite3
import pandas as pd
import openai
import re
import os

# ==========================================
# â˜… APIã‚­ãƒ¼è¨­å®š (æœ¬ç•ªç”¨å®‰å…¨ä»•æ§˜) â˜…
# ==========================================
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)

DB_NAME = 'm_league.db'

# DBæ¥ç¶šãƒ˜ãƒ«ãƒ‘ãƒ¼
def get_connection():
    return sqlite3.connect(DB_NAME)

# èµ·å‹•æ™‚ã«DBã‹ã‚‰åå‰ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
def get_db_vocabulary():
    print("--- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­è¾¼é–‹å§‹ ---")
    try:
        conn = get_connection()
        cur = conn.cursor()
        cur.execute("SELECT DISTINCT team FROM stats")
        teams = [r[0] for r in cur.fetchall() if r[0]]
        cur.execute("SELECT DISTINCT player FROM stats")
        players = [r[0] for r in cur.fetchall() if r[0]]
        conn.close()
        print(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: é¸æ‰‹{len(players)}å, ãƒãƒ¼ãƒ {len(teams)}ãƒãƒ¼ãƒ ")
        return ", ".join(teams), ", ".join(players)
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return "", ""

TEAM_VOCAB, PLAYER_VOCAB = get_db_vocabulary()
print("--- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­è¾¼å®Œäº† ---")

# â˜… ã‚µãƒ¼ãƒãƒ¼è¨ºæ–­ãƒšãƒ¼ã‚¸ (/debug)
@app.get("/debug")
def debug_endpoint():
    try:
        if not os.path.exists(DB_NAME):
            return {"status": "ERROR", "message": "DBãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"}
        conn = get_connection()
        df_stats = pd.read_sql_query("SELECT * FROM stats", conn)
        df_games = pd.read_sql_query("SELECT * FROM games", conn)
        conn.close()
        return {
            "status": "OK",
            "stats_count": len(df_stats),
            "games_count": len(df_games),
            "latest_date": df_games['date'].max() if not df_games.empty else "ãªã—"
        }
    except Exception as e:
        return {"status": "ERROR", "detail": str(e)}

class ChatRequest(BaseModel):
    message: str

# ==========================================
# â˜… ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ (/chat) â˜…
# ==========================================
@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    try:
        if not openai.api_key:
            return {"reply": "ã€ã‚¨ãƒ©ãƒ¼ã€‘APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Renderã®ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", "graph": None}

        user_query = req.message
        graph_data = None
        
        # ---------------------------------------------------------
        # 1. ã‚°ãƒ©ãƒ•ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰
        # ---------------------------------------------------------
        if "æ¨ç§»" in user_query or "ã‚°ãƒ©ãƒ•" in user_query:
            id_prompt = f"""
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œãƒã‚¤ãƒ³ãƒˆæ¨ç§»ã€ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã€‚è³ªå•: "{user_query}"
            ã€æ­£ã—ã„åå‰ã€‘ãƒãƒ¼ãƒ : {TEAM_VOCAB} é¸æ‰‹: {PLAYER_VOCAB}
            ã€æŒ‡ç¤ºã€‘è³ªå•å¯¾è±¡ã‚’ç‰¹å®šã—ã€LIKEæ¤œç´¢ã®SQLã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            ãƒ‘ã‚¿ãƒ¼ãƒ³A(ãƒãƒ¼ãƒ ): SELECT date, point, player FROM games WHERE player IN (SELECT player FROM stats WHERE team LIKE '%ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰%') ORDER BY date;
            ãƒ‘ã‚¿ãƒ¼ãƒ³B(å€‹äºº): SELECT date, point, player FROM games WHERE player LIKE '%ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰%' ORDER BY date;
            å›ç­”ã¯SQLã®ã¿ã€‚
            """
            res = openai.chat.completions.create(
                model="gpt-4o", messages=[{"role": "system", "content": id_prompt}], temperature=0
            )
            sql = res.choices[0].message.content.strip().replace("```sql", "").replace("```", "")
            print(f"ğŸ“Š ã‚°ãƒ©ãƒ•SQL: {sql}")
            
            conn = get_connection()
            try:
                df = pd.read_sql_query(sql, conn)
                if not df.empty:
                    df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.strftime('%Y/%m/%d')
                    df_grouped = df.groupby('date')['point'].sum().reset_index()
                    df_grouped['total_point'] = df_grouped['point'].cumsum()
                    
                    label_name = "æ¨ç§»"
                    if "team" in sql.lower():
                        label_name = "ãƒãƒ¼ãƒ æ¨ç§»"
                    elif not df.empty:
                        label_name = f"{df['player'].iloc[0]}ã®æ¨ç§»"

                    graph_data = {
                        "labels": df_grouped['date'].tolist(),
                        "data": df_grouped['total_point'].tolist(),
                        "label": label_name
                    }
                    final_prompt = f"""
                    Mãƒªãƒ¼ã‚°å®Ÿæ³è€…ã¨ã—ã¦è§£èª¬ã—ã¦ãã ã•ã„ã€‚
                    è³ªå•: {user_query}
                    ãƒ‡ãƒ¼ã‚¿: {df_grouped.tail(5).to_string()}
                    ã€Œã‚°ãƒ©ãƒ•ã‚’ã”è¦§ãã ã•ã„ã€ã¨æ·»ãˆã¦ãã ã•ã„ã€‚
                    """
                    res_text = openai.chat.completions.create(
                        model="gpt-4o", messages=[{"role": "system", "content": final_prompt}], temperature=0.3
                    )
                    return {"reply": res_text.choices[0].message.content, "graph": graph_data}
            except Exception as e:
                print(f"ã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
            finally:
                conn.close()

        # ---------------------------------------------------------
        # 2. ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå‹æ•—äºˆæƒ³ãƒ»å¯¾æˆ¦æˆç¸¾ï¼‰ â˜…ã“ã“ã«è¿½åŠ ã—ã¾ã—ãŸï¼
        # ---------------------------------------------------------
        elif "äºˆæƒ³" in user_query or "å¯¾æˆ¦" in user_query or "ç›¸æ€§" in user_query or "vs" in user_query.lower():
            # Step A: è³ªå•ã«å«ã¾ã‚Œã‚‹é¸æ‰‹åã‚’ç‰¹å®šã™ã‚‹
            extract_prompt = f"""
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰ã€åˆ†æå¯¾è±¡ã¨ãªã‚‹ã€Œé¸æ‰‹åã€ã‚’å…¨ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
            è³ªå•: "{user_query}"
            ã€é¸æ‰‹åç°¿ã€‘{PLAYER_VOCAB}
            å›ç­”ã¯é¸æ‰‹åã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºã™ã ã‘ã€‚ï¼ˆä¾‹: å¤šäº•éš†æ™´, ä¼Šé”æœ±é‡Œç´—ï¼‰
            ã‚‚ã—ãƒãƒ¼ãƒ åãŒæ›¸ã‹ã‚Œã¦ã„ãŸã‚‰ã€ãã®ãƒãƒ¼ãƒ ã®ä»£è¡¨çš„ãªé¸æ‰‹ã‚’1åé¸ã‚“ã§ãã ã•ã„ã€‚
            """
            res_names = openai.chat.completions.create(
                model="gpt-4o", messages=[{"role": "system", "content": extract_prompt}], temperature=0
            )
            target_names = [n.strip() for n in res_names.choices[0].message.content.split(',') if n.strip()]
            
            if not target_names:
                return {"reply": "åˆ†æå¯¾è±¡ã®é¸æ‰‹åãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚é¸æ‰‹åã‚’å…¥ã‚Œã¦è³ªå•ã—ã¦ãã ã•ã„ã€‚", "graph": None}

            conn = get_connection()
            try:
                # Step B: å„é¸æ‰‹ã®ã€Œé€šç®—ã‚¹ã‚¿ãƒƒãƒ„ã€ã‚’å–å¾—
                placeholders = ",".join(["?"] * len(target_names))
                sql_stats = f"SELECT * FROM stats WHERE player IN ({placeholders})"
                df_stats = pd.read_sql_query(sql_stats, conn, params=target_names)
                
                # Step C: å„é¸æ‰‹ã®ã€Œç›´è¿‘5è©¦åˆã€ã‚’å–å¾—ï¼ˆèª¿å­ã‚’è¦‹ã‚‹ãŸã‚ï¼‰
                recent_data_text = ""
                for p in target_names:
                    sql_recent = "SELECT date, rank, point FROM games WHERE player = ? ORDER BY date DESC LIMIT 5"
                    df_recent = pd.read_sql_query(sql_recent, conn, params=[p])
                    if not df_recent.empty:
                        recent_data_text += f"\nã€{p}ã®ç›´è¿‘5æˆ¦ã€‘\n{df_recent.to_string(index=False)}\n"

                # Step D: ã‚¢ãƒŠãƒªã‚¹ãƒˆAIã«åˆ†æã•ã›ã‚‹
                final_prompt = f"""
                ã‚ãªãŸã¯Mãƒªãƒ¼ã‚°ã®ãƒ—ãƒ­ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
                ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: "{user_query}"
                
                ä»¥ä¸‹ã®ã€Œå®¢è¦³çš„ãªãƒ‡ãƒ¼ã‚¿ã€ã‚’å…ƒã«ã€è«–ç†çš„ãªåˆ†æãƒ»äºˆæƒ³ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
                
                ã€å¯¾è±¡é¸æ‰‹ã®ä»ŠæœŸã‚¹ã‚¿ãƒƒãƒ„ã€‘
                {df_stats.to_string(index=False)}
                
                ã€å¯¾è±¡é¸æ‰‹ã®ç›´è¿‘æˆç¸¾ï¼ˆå‹¢ã„ï¼‰ã€‘
                {recent_data_text}
                
                ã€æŒ‡ç¤ºã€‘
                - ã€Œå‹æ•—äºˆæƒ³ã€ã®å ´åˆã¯ã€ã‚¹ã‚¿ãƒƒãƒ„ï¼ˆå¹³å‡ç€é †ã‚„ãƒã‚¤ãƒ³ãƒˆï¼‰ã¨ç›´è¿‘ã®å‹¢ã„ã‚’ç·åˆã—ã¦ã€æœ€ã‚‚å‹ç‡ãŒé«˜ãã†ãªé¸æ‰‹ã‚’1åæŒ™ã’ã€ç†ç”±ã‚’è§£èª¬ã—ã¦ãã ã•ã„ã€‚
                - ã€Œå¯¾æˆ¦æˆç¸¾ãƒ»ç›¸æ€§ã€ã®å ´åˆã¯ã€ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã®å¼·ã¿ï¼ˆæ”»æ’ƒå‹ã‹å®ˆå‚™å‹ã‹ãªã©ï¼‰ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚
                - æœ€å¾Œã«å¿…ãšã€Œâ€»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãäºˆæƒ³ã§ã‚ã‚Šã€çµæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€ã¨æ³¨é‡ˆã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
                """
                res_final = openai.chat.completions.create(
                    model="gpt-4o", messages=[{"role": "system", "content": final_prompt}], temperature=0.7
                )
                return {"reply": res_final.choices[0].message.content, "graph": None}
            finally:
                conn.close()

        # ---------------------------------------------------------
        # 3. æœ€æ–°çµæœãƒ»é †ä½ãƒ¢ãƒ¼ãƒ‰
        # ---------------------------------------------------------
        elif "é †ä½" in user_query or "ãƒ©ãƒ³ã‚­ãƒ³ã‚°" in user_query or "æœ€æ–°" in user_query or "è©¦åˆçµæœ" in user_query:
            conn = get_connection()
            try:
                sql_games = "SELECT date, game_count, rank, player, point FROM games ORDER BY date DESC, game_count DESC, rank ASC LIMIT 8"
                df_games = pd.read_sql_query(sql_games, conn)
                sql_ranking = "SELECT rank, team, point FROM team_ranking ORDER BY rank"
                df_ranking = pd.read_sql_query(sql_ranking, conn)
                combined_data = f"ã€ç›´è¿‘ã®è©¦åˆçµæœã€‘\n{df_games.to_string()}\n\nã€ç¾åœ¨ã®ãƒãƒ¼ãƒ é †ä½ã€‘\n{df_ranking.to_string()}"
                
                final_prompt = f"""
                ã‚ãªãŸã¯Mãƒªãƒ¼ã‚°ã®å…¬å¼ãƒªãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
                è³ªå•ã€Œ{user_query}ã€ã«å¯¾ã—ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«è¦‹ã‚„ã™ãå ±å‘Šã—ã¦ãã ã•ã„ã€‚
                ã€ãƒ‡ãƒ¼ã‚¿ã€‘{combined_data}
                ã€é‡è¦ï¼šè¡¨ç¤ºãƒ«ãƒ¼ãƒ«ã®å³å®ˆã€‘
                1. **ãƒã‚¤ãƒ•ãƒ³ã€Œ-ã€ã‚’åŒºåˆ‡ã‚Šæ–‡å­—ã«ä½¿ã‚ãªã„ã§ãã ã•ã„**ã€‚
                2. ãƒãƒ¼ãƒ é †ä½ã¯ã€Œ1ä½: **ãƒãƒ¼ãƒ å** (540.0pt)ã€ã®å½¢å¼ã§ã€‚
                3. ãƒã‚¤ãƒŠã‚¹ã®ãƒã‚¤ãƒ³ãƒˆã¯ `â–²` ã¾ãŸã¯ `-` ã‚’æ•°å­—ã®ç›´å‰ã«ã¤ã‘ã¦ãã ã•ã„ã€‚
                4. é †ä½ã«å¿œã˜ãŸçµµæ–‡å­—(ğŸ¥‡,ğŸ¥ˆ,ğŸ¥‰,4ï¸âƒ£,ğŸ†)ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
                5. ãƒãƒ¼ãƒ åã‚„é¸æ‰‹åã¯ **å¤ªå­—** ã«ã—ã¦ãã ã•ã„ã€‚
                """
                res_final = openai.chat.completions.create(
                    model="gpt-4o", messages=[{"role": "system", "content": final_prompt}], temperature=0.3
                )
                return {"reply": res_final.choices[0].message.content, "graph": None}
            except Exception as e:
                return {"reply": f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", "graph": None}
            finally:
                conn.close()

        # ---------------------------------------------------------
        # 4. é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
        # ---------------------------------------------------------
        sql_prompt = f"""
        ã‚ãªãŸã¯Mãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
        è³ªå•ã€Œ{user_query}ã€ã«å¯¾ã—ã€é©åˆ‡ãªSQLã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        ã€æ­£ã—ã„åå‰ã€‘é¸æ‰‹: {PLAYER_VOCAB} ãƒãƒ¼ãƒ : {TEAM_VOCAB}
        ã€æŒ‡ç¤ºã€‘ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ä¸Šè¨˜ãƒªã‚¹ãƒˆã®åå‰ã«å¤‰æ›ã—ã€LIKEæ¤œç´¢ã—ã¦ãã ã•ã„ã€‚
        å›ç­”ã¯SQLã®ã¿ã€‚
        """
        res_sql = openai.chat.completions.create(
            model="gpt-4o", messages=[{"role": "system", "content": sql_prompt}], temperature=0
        )
        gen_sql = res_sql.choices[0].message.content.strip().replace("```sql", "").replace("```", "")
        print(f"ğŸ’¬ é€šå¸¸SQL: {gen_sql}")
        
        conn = get_connection()
        try:
            df_result = pd.read_sql_query(gen_sql, conn)
        except:
            df_result = pd.DataFrame()
        finally:
            conn.close()

        final_prompt = f"""
        Mãƒªãƒ¼ã‚°è§£èª¬è€…ã¨ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
        è³ªå•: {user_query}
        ãƒ‡ãƒ¼ã‚¿: {df_result.to_string()}
        ã€è¡¨ç¤ºãƒ«ãƒ¼ãƒ«ã€‘
        - åŒºåˆ‡ã‚Šæ–‡å­—ã¨ã—ã¦ãƒã‚¤ãƒ•ãƒ³ã€Œ-ã€ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
        - ã€Œé …ç›®å: å€¤ã€ã®å½¢å¼ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
        - ãƒ‡ãƒ¼ã‚¿ãŒè¦‹å½“ãŸã‚‰ãªã„å ´åˆã¯æ­£ç›´ã«ä¼ãˆã¦ãã ã•ã„ã€‚
        """
        res_final = openai.chat.completions.create(
            model="gpt-4o", messages=[{"role": "system", "content": final_prompt}], temperature=0.3
        )
        return {"reply": res_final.choices[0].message.content, "graph": None}

    except Exception as e:
        return {"reply": f"ã‚¨ãƒ©ãƒ¼: {str(e)}", "graph": None}